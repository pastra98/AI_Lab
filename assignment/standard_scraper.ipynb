{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Scraping _derstandard.at_\n",
    "\n",
    " **TODO:** talk about some legal stuff with scraping\n",
    "\n",
    " First we define the function `get_standard_soup()`, which sends a request to derstandard, along with a cookie that derstandard checks if a user has accepted their DSGVO notice. If this cookie is not sent, a banner is displayed and the html is only partially loaded.\n",
    "\n",
    " Secondly, we define `get_frontpage_articles()`, which expects a bs4 soup object of a frontpage. While derstandard no longer offers an archive, the frontpage articles of a given day can be conveniently accessed with the pattern `frontpage/y/m/d`. Each frontpage contains article sections which contain the (sub)heading, lead, number of comments, storylabels etc.\n",
    "\n",
    " We will start by pulling the frontpage of december 22th 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have fetched 137 articles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# fetch the html content of a derstandard.at page\n",
    "def get_standard_soup(link):\n",
    "    response = requests.get(link, cookies={'DSGVO_ZUSAGE_V1': 'true'})\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# generate a dictionary of articles with title as key and the bs4 element as value\n",
    "def get_frontpage_articles(soup):\n",
    "    articles_dict = {}\n",
    "    articles = soup.select('div.chronological>section article')\n",
    "    for article in articles:\n",
    "        title_tag = article.find('a')\n",
    "        if title_tag and title_tag.has_attr('title'):\n",
    "            title = title_tag['title']\n",
    "            articles_dict[title] = article\n",
    "    return articles_dict\n",
    "\n",
    "# Generate the articles dictionary for an arbitrary frontpage\n",
    "soup = get_standard_soup('https://www.derstandard.at/frontpage/2023/12/22')\n",
    "articles_dict = get_frontpage_articles(soup)\n",
    "\n",
    "print(f'We have fetched {len(articles_dict)} articles\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the next step, lets look at the information we can get from those article sections on the frontpage. By inspecting the html, we have already identified various elements that we will use in the subsequent steps:\n",
    " * title\n",
    " * subtitle\n",
    " * article type\n",
    " * link\n",
    " * datetime\n",
    " * kicker (like an additional tag, not 100% about its meaning yet)\n",
    " * postingcount\n",
    " * storylabels\n",
    "\n",
    " while playing with the data, we noticed that not every article contains storylabels. We will check this in the following step, as well as if every article tag has a type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles without data-type attribute: 0\n",
      "Number of articles without storylabels: 104\n",
      "Number of articles with story attribute: 33\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze attributes of specified tags and their attributes\n",
    "def analyze_tag_attributes(articles_dict):\n",
    "    no_data_type = set()\n",
    "    no_story_label = set()\n",
    "\n",
    "    for title, article in articles_dict.items():\n",
    "        # Check if every article tag has a data-type attribute - basically the type of the article\n",
    "        if not article.has_attr('data-type'):\n",
    "            no_data_type.add(title)\n",
    "        # search for <div class=\"storylabels\"> in articles - the story labels\n",
    "        if not article.find('div', class_='storylabels'):\n",
    "            no_story_label.add(title)\n",
    "\n",
    "    return no_data_type, no_story_label\n",
    "\n",
    "no_data_type, no_story_label = analyze_tag_attributes(articles_dict)\n",
    "print(f'Number of articles without data-type attribute: {len(no_data_type)}')\n",
    "print(f'Number of articles without storylabels: {len(no_story_label)}')\n",
    "# get articles that have a story label\n",
    "has_label = set(articles_dict.keys()).difference(no_story_label)\n",
    "print(f'Number of articles with story attribute: {len(has_label)}')\n",
    "\n",
    "# a lot of articles do not have a story label, maybe an interesting goal for machine learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All articles have a data-type, but only a few articles have story attributes. This could be an interesting labeling task for our machine learning project later.\n",
    " Next, we print out the html of two articles to show the data we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No storylabel:\n",
      "<article class=\"fig\" data-dg=\"p1-43\" data-dt=\"7x2\" data-mg=\"p1-43\" data-mt=\"4x4\" data-type=\"story\">\n",
      "<div class=\"teaser-inner\">\n",
      "<a href=\"/story/3000000200853/trump-uebte-laut-medienbericht-druck-auf-wahlpruefer-in-michigan-aus\" title=\"Trump übte laut Medienbericht Druck auf Wahlprüfer in Michigan aus\">\n",
      "<figure data-type=\"image\">\n",
      "<picture>\n",
      "<source data-lazy-srcset=\"https://i.ds.at/V3WkIw/c:1200:800:fp:0.500:0.500/rs:fill:280:187/g:fp:0.54:0.29/plain/lido-images/2023/12/22/3f9fca60-5573-4475-8e22-0cd35d00484b.jpeg\" media=\"(min-width: 960px)\"/>\n",
      "<source data-lazy-srcset=\"https://i.ds.at/KnrHlA/c:1200:800:fp:0.500:0.500/rs:fill:750:375/g:fp:0.54:0.29/plain/lido-images/2023/12/22/3f9fca60-5573-4475-8e22-0cd35d00484b.jpeg\" media=\"(max-width: 959px)\"/>\n",
      "<img alt=\"Election_2024-President-New_Mexico_69156\" data-lazy-src=\"https://i.ds.at/WDo_zA/rs:fill:600:400/plain/lido-images/2023/12/22/3f9fca60-5573-4475-8e22-0cd35d00484b.jpeg\" referrerpolicy=\"unsafe-url\"/>\n",
      "</picture>\n",
      "</figure>\n",
      "<header>\n",
      "<time datetime=\"2023-12-22T14:38\n",
      "\">14:38\n",
      "</time>\n",
      "<p class=\"teaser-kicker\">USA</p>\n",
      "<div class=\"teaser-postingcount\">25 <span>Postings</span>\n",
      "</div>\n",
      "<h1 class=\"teaser-title\">Trump übte laut Medienbericht Druck auf Wahlprüfer in Michigan aus </h1>\n",
      "<p class=\"teaser-subtitle\">Der <span class=\"hyphenate\">Ex-US-Präsident</span> soll versucht haben, zwei Wahlprüfer von einer Bestätigung der Wahlresultate abzuhalten </p>\n",
      "</header>\n",
      "</a>\n",
      "</div>\n",
      "</article>\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "With storylabel:\n",
      "<article class=\"fig\" data-dg=\"p1-132\" data-dt=\"7x2\" data-mg=\"p1-132\" data-mt=\"4x4\" data-type=\"story\">\n",
      "<div class=\"teaser-inner\">\n",
      "<a href=\"/story/3000000200661/baerige-weihnachten-in-schoenbrunn\" title=\"Bärige Weihnachten in Schönbrunn\">\n",
      "<figure data-type=\"image\">\n",
      "<picture>\n",
      "<source data-lazy-srcset=\"https://i.ds.at/oT-PeQ/c:1620:1080:fp:0.500:0.500/rs:fill:280:187/plain/lido-images/2023/12/21/0dc7ec6e-fd95-4be8-94ca-801ed067dfb6.jpeg\" media=\"(min-width: 960px)\"/>\n",
      "<source data-lazy-srcset=\"https://i.ds.at/xmQSZA/c:1620:1080:fp:0.500:0.500/rs:fill:750:375/plain/lido-images/2023/12/21/0dc7ec6e-fd95-4be8-94ca-801ed067dfb6.jpeg\" media=\"(max-width: 959px)\"/>\n",
      "<img alt=\"Bärige Weihnachten in Schönbrunn\" data-lazy-src=\"https://i.ds.at/bhX0lA/rs:fill:600:400/plain/lido-images/2023/12/21/0dc7ec6e-fd95-4be8-94ca-801ed067dfb6.jpeg\" referrerpolicy=\"unsafe-url\"/>\n",
      "</picture>\n",
      "<time class=\"duration\">01:03</time>\n",
      "</figure>\n",
      "<header>\n",
      "<time datetime=\"2023-12-22T06:00\n",
      "\">06:00\n",
      "</time>\n",
      "<p class=\"teaser-kicker\">Weihnachten</p>\n",
      "<div class=\"teaser-postingcount\">1 <span>Posting</span>\n",
      "</div>\n",
      "<h1 class=\"teaser-title\">Bärige Weihnachten in Schönbrunn </h1>\n",
      "<p class=\"teaser-subtitle\">Für die Schönbrunner Brillenbären hat es bereits vor den Feiertagen eine weihnachtliche Überraschung vom <span class=\"hyphenate\">Tierpflegerteam</span> gegeben: einen Christbaum geschmückt unter anderem mit <span class=\"hyphenate\">Karottenlametta</span> und <span class=\"hyphenate\">Paprikaringerln</span> </p>\n",
      "<time class=\"duration\">01:03</time>\n",
      "<div class=\"storylabels\">\n",
      "<span data-label-category=\"indepth\" data-label-name=\"Video\">Video</span>\n",
      "</div>\n",
      "</header>\n",
      "</a>\n",
      "</div>\n",
      "</article>\n"
     ]
    }
   ],
   "source": [
    "# example of an article without story label\n",
    "print(f'No storylabel:\\n{articles_dict[list(no_story_label)[0]]}\\n')\n",
    "print(80*'-')\n",
    "\n",
    "# articles with story label \n",
    "print(f'With storylabel:\\n{articles_dict[list(has_label)[0]]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is the information one can get from the frontpage. Later we will also follow the links and scrape additional data from the articles, but lets first focus on getting a dataset just based on the information that can be attained from the frontpage.\n",
    "\n",
    " To this end, we define `extract_article_data()`, which uses the dictionary following the pattern `article_title: article_section_soup`. From the html (soup), we will extract and clean:\n",
    "\n",
    " * title\n",
    " * teaser-subtitle\n",
    " * link\n",
    " * time\n",
    " * teaser-kicker\n",
    " * n_posts\n",
    " * storylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Jesus-Geburt unter Palmen',\n",
       "  'teaser-subtitle': 'Auch der Koran erzählt über die Geburt von Jesus Christus. Nicht als Sohn Gottes, aber als Sohn Marias, die als Frau im Koran eine besondere Stellung einnimt',\n",
       "  'link': 'https://www.derstandard.at/story/3000000200744/jesus-geburt-unter-palmen',\n",
       "  'time': '2023-12-22T06:00',\n",
       "  'teaser-kicker': 'Wussten Sie schon?',\n",
       "  'n_posts': 1,\n",
       "  'storylabels': None},\n",
       " {'title': '\"Aquaman and the Lost Kingdom\" scheitert an versuchter Schadensbegrenzung',\n",
       "  'teaser-subtitle': 'Der Erfolg derSuperheldenfilmeleidet immer öfter unter den privaten Problemen ihrerHauptdarsteller.Der Fortsetzung von \"Aquaman\" droht auch deshalb ein Flop',\n",
       "  'link': 'https://www.derstandard.at/story/3000000200724/aquaman-and-the-lost-kingdom-scheitert-an-versuchter-schadensbegrenzung',\n",
       "  'time': '2023-12-22T06:00',\n",
       "  'teaser-kicker': 'Im Kino',\n",
       "  'n_posts': 242,\n",
       "  'storylabels': None},\n",
       " {'title': 'One-Man-Show mit fatalen Folgen für die Demokratie in Serbien',\n",
       "  'teaser-subtitle': 'Die Wahlen in Serbien waren eine Farce. Die Europäische Union hat bisher auf einen pragmatischen Kuschelkurs gesetzt. Damit könnte es jetzt aber vorbei sein. Für eine härtere Gangart wäre es auch höchste Zeit',\n",
       "  'link': 'https://www.derstandard.at/story/3000000200698/one-man-show-mit-fatalen-folgen-fuer-die-demokratie-in-serbien',\n",
       "  'time': '2023-12-22T06:00',\n",
       "  'teaser-kicker': 'Vedran Džihić',\n",
       "  'n_posts': 112,\n",
       "  'storylabels': 'Kommentar der anderen'},\n",
       " {'title': 'David Alaba zum zehnten Mal zu Österreichs Fußballer des Jahres gekürt',\n",
       "  'teaser-subtitle': 'Zehn von zwölf Trainern wählten den derzeit verletztenReal-Verteidigerauf Rang eins. Für den Wiener ist es der vierte Erfolg in Serie',\n",
       "  'link': 'https://www.derstandard.at/story/3000000200745/david-alaba-zum-10-mal-fu223baller-des-jahres-riesige-ehre',\n",
       "  'time': '2023-12-22T05:46',\n",
       "  'teaser-kicker': 'Fußball',\n",
       "  'n_posts': 33,\n",
       "  'storylabels': None},\n",
       " {'title': 'Kreuzworträtsel F 10571',\n",
       "  'teaser-subtitle': 'Täglich neu, exklusiv fürSmart-Abonnent:innen:Das kniffligephoenixen-Rätseldes STANDARD',\n",
       "  'link': 'https://www.derstandard.at/story/3000000199163/kreuzwortraetsel-f-10571',\n",
       "  'time': '2023-12-22T00:01',\n",
       "  'teaser-kicker': 'Kreuzworträtsel',\n",
       "  'n_posts': 4,\n",
       "  'storylabels': 'Spiel'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract specific data from each article\n",
    "def extract_article_data(articles_dict):\n",
    "    HOST = 'https://www.derstandard.at'\n",
    "    article_data = []\n",
    "    \n",
    "    for title, article in articles_dict.items():\n",
    "        data = {\n",
    "            'title': title,\n",
    "            'teaser-subtitle': None,\n",
    "            'link': None,\n",
    "            'time': None,\n",
    "            'teaser-kicker': None,\n",
    "            'n_posts': None,\n",
    "            'storylabels': None\n",
    "        }\n",
    "\n",
    "        # most links are relative, so we need to add the host\n",
    "        link = article.find('a')['href']\n",
    "        if not link.startswith(HOST):\n",
    "            link = HOST + link\n",
    "        data['link'] = link\n",
    "        \n",
    "        # for live articles, there is a second time tag with the duration of the live post\n",
    "        # however, we only care about the time of publication here\n",
    "        time = [tag for tag in article.find_all('time') if 'datetime' in tag.attrs][0]\n",
    "        data['time'] = time['datetime'].rstrip('\\r\\n')\n",
    "\n",
    "        # if there are no comments, the string is empty so set it to 0\n",
    "        n_posts = article.find('div', 'teaser-postingcount')\n",
    "        try: data['n_posts'] = int(n_posts.get_text(strip=True).rstrip('Posting').replace('.', ''))\n",
    "        except: data['n_posts'] = 0\n",
    "        \n",
    "        # Extracting other specified tags\n",
    "        for tag, class_name in [('p', 'teaser-kicker'), \n",
    "                                ('p', 'teaser-subtitle'), \n",
    "                                ('div', 'storylabels')]:\n",
    "            found_tag = article.find(tag, class_=class_name)\n",
    "            if found_tag:\n",
    "                data[class_name] = found_tag.get_text(strip=True)\n",
    "\n",
    "        article_data.append(data)\n",
    "\n",
    "    return article_data\n",
    "\n",
    "article_data = extract_article_data(articles_dict)\n",
    "# last 5 articles, of which some have a story label\n",
    "article_data[-5:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The various attributes will be analyzed once we convert our data to a dataframe.\n",
    "\n",
    "But before we start scraping like mad, lets check robots.txt such that we can comply with derstandards scraping policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-agent: *\n",
      "\n",
      "Disallow: /profil/\n",
      "\n",
      "Sitemap: https://www.derstandard.at/sitemaps/news.xml\n",
      "Sitemap: https://www.derstandard.at/sitemaps/sitemap.xml\n",
      "\n",
      "Crawl-delay: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_24276\\4133154167.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(response.content, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "print(get_standard_soup('https://www.derstandard.at/robots.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Craw-delay: 1`, so lets be nice and wait 1 second between requests. Then we'll scrape the frontpage of every day in 2023 until the 20th of december and save the data as a csv.\n",
    "\n",
    "**Caution:** you might not want to run this cell, as it takes about ~13 minutes to run. The data has already been extracted once and has been saved to `data/derstandard_frontpage_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1462/1462 [46:44<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def scrape_frontpage(start_date: str, end_date: str, logging=False):\n",
    "    # Validate that dates follow the pattern YYYY-MM-DD\n",
    "    try:\n",
    "        start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "        return\n",
    "\n",
    "    data = []\n",
    "    # all dates between start and end (inclusive)\n",
    "    delta = end - start\n",
    "    for i in tqdm(range(delta.days + 1)):\n",
    "        # generate link for each day\n",
    "        day = start + timedelta(days=i)\n",
    "        date = day.strftime('%Y/%m/%d')\n",
    "        link = f'https://www.derstandard.at/frontpage/{date}'\n",
    "        # make a request to the link and extract the data\n",
    "        article_dict = get_frontpage_articles(get_standard_soup(link))\n",
    "        articles = extract_article_data(article_dict)\n",
    "        if logging:\n",
    "            print(f'Fetched {len(articles)} articles from {date}')\n",
    "        data += articles\n",
    "        # wait almost a second before next request, our data processing takes a bit of time as well\n",
    "        sleep(0.8)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# scrape the data for 4 years\n",
    "data = scrape_frontpage('2019-12-22', '2023-12-22')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this cell took a while to run obviously, but we finally have our precious data. Lets convert it to a dataframe and see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>link</th>\n",
       "      <th>datetime</th>\n",
       "      <th>kicker</th>\n",
       "      <th>n_posts</th>\n",
       "      <th>storylabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real Madrid stolpert mit Aluminiumpech im Tite...</td>\n",
       "      <td>Die Königlichen können Bilbao daheim nicht bes...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112599363...</td>\n",
       "      <td>2019-12-22T23:44</td>\n",
       "      <td>Primera Division</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolivien weist venezolanische Diplomaten aus</td>\n",
       "      <td>InterimspräsidentinJeanine Áñez wirft denBotsc...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598924...</td>\n",
       "      <td>2019-12-22T22:50</td>\n",
       "      <td>Übergangsregierung</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erdoğan warnt vor neuer Flüchtlingswelle aus S...</td>\n",
       "      <td>Türkischer Präsident: \"80.000 Menschen Richtun...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598130...</td>\n",
       "      <td>2019-12-22T21:43</td>\n",
       "      <td>Bürgerkrieg</td>\n",
       "      <td>104</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Massenkarambolage mit 63 Fahrzeugen in Virginia</td>\n",
       "      <td>Autos stießen auf vereister Brücke zusammen</td>\n",
       "      <td>https://www.derstandard.at/story/2000112597972...</td>\n",
       "      <td>2019-12-22T21:29</td>\n",
       "      <td>Weihnachtsverkehr</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salzburg schlägt Caps, Meister KAC mit vierter...</td>\n",
       "      <td>Die Bullen sind damit der Gewinner der Runde: ...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112595206...</td>\n",
       "      <td>2019-12-22T20:54</td>\n",
       "      <td>Eishockey</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182102</th>\n",
       "      <td>Wer braucht die Kirche?</td>\n",
       "      <td>Dass sich die Kirche nach soschwerwiegendenVer...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200743...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Dominik Straub</td>\n",
       "      <td>1</td>\n",
       "      <td>Kommentar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182103</th>\n",
       "      <td>Sonderregelung verlängert: Mehr als 1.000 Ärzt...</td>\n",
       "      <td>Der\"Pandemieparagraf\"im Ärztegesetz hat mehr a...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200621...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Pandemieparagraf</td>\n",
       "      <td>148</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182104</th>\n",
       "      <td>Stadtforscher: \"Architektur ist Teil unserer W...</td>\n",
       "      <td>Jetzt anhören: In Zukunft müssen Städte wieder...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200499...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Edition Zukunft</td>\n",
       "      <td>54</td>\n",
       "      <td>Podcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182105</th>\n",
       "      <td>David Alaba zum zehnten Mal zu Österreichs Fuß...</td>\n",
       "      <td>Zehn von zwölf Trainern wählten den derzeit ve...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200745...</td>\n",
       "      <td>2023-12-22T05:46</td>\n",
       "      <td>Fußball</td>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182106</th>\n",
       "      <td>Kreuzworträtsel F 10571</td>\n",
       "      <td>Täglich neu, exklusiv fürSmart-Abonnent:innen:...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000199163...</td>\n",
       "      <td>2023-12-22T00:01</td>\n",
       "      <td>Kreuzworträtsel</td>\n",
       "      <td>4</td>\n",
       "      <td>Spiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182107 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0       Real Madrid stolpert mit Aluminiumpech im Tite...   \n",
       "1            Bolivien weist venezolanische Diplomaten aus   \n",
       "2       Erdoğan warnt vor neuer Flüchtlingswelle aus S...   \n",
       "3         Massenkarambolage mit 63 Fahrzeugen in Virginia   \n",
       "4       Salzburg schlägt Caps, Meister KAC mit vierter...   \n",
       "...                                                   ...   \n",
       "182102                            Wer braucht die Kirche?   \n",
       "182103  Sonderregelung verlängert: Mehr als 1.000 Ärzt...   \n",
       "182104  Stadtforscher: \"Architektur ist Teil unserer W...   \n",
       "182105  David Alaba zum zehnten Mal zu Österreichs Fuß...   \n",
       "182106                            Kreuzworträtsel F 10571   \n",
       "\n",
       "                                                 subtitle  \\\n",
       "0       Die Königlichen können Bilbao daheim nicht bes...   \n",
       "1       InterimspräsidentinJeanine Áñez wirft denBotsc...   \n",
       "2       Türkischer Präsident: \"80.000 Menschen Richtun...   \n",
       "3             Autos stießen auf vereister Brücke zusammen   \n",
       "4       Die Bullen sind damit der Gewinner der Runde: ...   \n",
       "...                                                   ...   \n",
       "182102  Dass sich die Kirche nach soschwerwiegendenVer...   \n",
       "182103  Der\"Pandemieparagraf\"im Ärztegesetz hat mehr a...   \n",
       "182104  Jetzt anhören: In Zukunft müssen Städte wieder...   \n",
       "182105  Zehn von zwölf Trainern wählten den derzeit ve...   \n",
       "182106  Täglich neu, exklusiv fürSmart-Abonnent:innen:...   \n",
       "\n",
       "                                                     link          datetime  \\\n",
       "0       https://www.derstandard.at/story/2000112599363...  2019-12-22T23:44   \n",
       "1       https://www.derstandard.at/story/2000112598924...  2019-12-22T22:50   \n",
       "2       https://www.derstandard.at/story/2000112598130...  2019-12-22T21:43   \n",
       "3       https://www.derstandard.at/story/2000112597972...  2019-12-22T21:29   \n",
       "4       https://www.derstandard.at/story/2000112595206...  2019-12-22T20:54   \n",
       "...                                                   ...               ...   \n",
       "182102  https://www.derstandard.at/story/3000000200743...  2023-12-22T06:00   \n",
       "182103  https://www.derstandard.at/story/3000000200621...  2023-12-22T06:00   \n",
       "182104  https://www.derstandard.at/story/3000000200499...  2023-12-22T06:00   \n",
       "182105  https://www.derstandard.at/story/3000000200745...  2023-12-22T05:46   \n",
       "182106  https://www.derstandard.at/story/3000000199163...  2023-12-22T00:01   \n",
       "\n",
       "                    kicker  n_posts storylabels  \n",
       "0         Primera Division       30        None  \n",
       "1       Übergangsregierung       16        None  \n",
       "2              Bürgerkrieg      104        None  \n",
       "3        Weihnachtsverkehr       35        None  \n",
       "4                Eishockey        4        None  \n",
       "...                    ...      ...         ...  \n",
       "182102      Dominik Straub        1   Kommentar  \n",
       "182103    Pandemieparagraf      148        None  \n",
       "182104     Edition Zukunft       54     Podcast  \n",
       "182105             Fußball       34        None  \n",
       "182106     Kreuzworträtsel        4       Spiel  \n",
       "\n",
       "[182107 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = df.columns.str.replace('teaser-', '')\n",
    "df.rename(columns={'time': 'datetime'}, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over 182 thousand rows, this should give us plenty data to analyze!\n",
    "\n",
    "Lets save it to a csv, totalling 57mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/4yrs_derstandard_frontpage_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
