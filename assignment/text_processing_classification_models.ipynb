{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes the scraped data, converts text columns to numeric vectors (Part 1) and trains classification models using the processed text data as predictors.\n",
    "\n",
    "Locally on Richard's computer, the notebook takes approximately 1.5 hrs to execute completely - Part 1 needs ~45 mins, Part 2 and 3 ~20 min each.\n",
    "\n",
    "Besides usual numpy, pandas etc., needed modules are spacy and pytorch. The German NLP model needs to be downloaded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Text Processing\n",
    "\n",
    "Here we import scraped data, splits text column to words, extracts and normalizes tokens. Next, tokens are converted to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die ganze Stadt ist ein Startup: Shenzhen ist das Silicon Valley für Hardware-Firmen\n",
      "Die DET nk\n",
      "ganze ADJ nk\n",
      "Stadt NOUN sb\n",
      "ist AUX ROOT\n",
      "ein DET nk\n",
      "Startup NOUN pd\n",
      ": PUNCT punct\n",
      "Shenzhen NOUN sb\n",
      "ist AUX cj\n",
      "das DET nk\n",
      "Silicon PROPN pnc\n",
      "Valley PROPN sb\n",
      "für ADP mnr\n",
      "Hardware-Firmen NOUN nk\n"
     ]
    }
   ],
   "source": [
    "### Setup\n",
    "\n",
    "# pip install spacy\n",
    "# python -m spacy download de_core_news_sm  - for small model (13 MB)\n",
    "# python -m spacy download de_core_news_md  - for medium model (42 MB)\n",
    "# source - https://spacy.io/models/de\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.de.examples import sentences \n",
    "\n",
    "\n",
    "# Example from documentation\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>link</th>\n",
       "      <th>datetime</th>\n",
       "      <th>kicker</th>\n",
       "      <th>n_posts</th>\n",
       "      <th>storylabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real Madrid stolpert mit Aluminiumpech im Tite...</td>\n",
       "      <td>Die Königlichen können Bilbao daheim nicht bes...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112599363...</td>\n",
       "      <td>2019-12-22T23:44</td>\n",
       "      <td>Primera Division</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolivien weist venezolanische Diplomaten aus</td>\n",
       "      <td>InterimspräsidentinJeanine Áñez wirft denBotsc...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598924...</td>\n",
       "      <td>2019-12-22T22:50</td>\n",
       "      <td>Übergangsregierung</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erdoğan warnt vor neuer Flüchtlingswelle aus S...</td>\n",
       "      <td>Türkischer Präsident: \"80.000 Menschen Richtun...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598130...</td>\n",
       "      <td>2019-12-22T21:43</td>\n",
       "      <td>Bürgerkrieg</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Massenkarambolage mit 63 Fahrzeugen in Virginia</td>\n",
       "      <td>Autos stießen auf vereister Brücke zusammen</td>\n",
       "      <td>https://www.derstandard.at/story/2000112597972...</td>\n",
       "      <td>2019-12-22T21:29</td>\n",
       "      <td>Weihnachtsverkehr</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salzburg schlägt Caps, Meister KAC mit vierter...</td>\n",
       "      <td>Die Bullen sind damit der Gewinner der Runde: ...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112595206...</td>\n",
       "      <td>2019-12-22T20:54</td>\n",
       "      <td>Eishockey</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182102</th>\n",
       "      <td>Wer braucht die Kirche?</td>\n",
       "      <td>Dass sich die Kirche nach soschwerwiegendenVer...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200743...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Dominik Straub</td>\n",
       "      <td>1</td>\n",
       "      <td>Kommentar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182103</th>\n",
       "      <td>Sonderregelung verlängert: Mehr als 1.000 Ärzt...</td>\n",
       "      <td>Der\"Pandemieparagraf\"im Ärztegesetz hat mehr a...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200621...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Pandemieparagraf</td>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182104</th>\n",
       "      <td>Stadtforscher: \"Architektur ist Teil unserer W...</td>\n",
       "      <td>Jetzt anhören: In Zukunft müssen Städte wieder...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200499...</td>\n",
       "      <td>2023-12-22T06:00</td>\n",
       "      <td>Edition Zukunft</td>\n",
       "      <td>54</td>\n",
       "      <td>Podcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182105</th>\n",
       "      <td>David Alaba zum zehnten Mal zu Österreichs Fuß...</td>\n",
       "      <td>Zehn von zwölf Trainern wählten den derzeit ve...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000200745...</td>\n",
       "      <td>2023-12-22T05:46</td>\n",
       "      <td>Fußball</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182106</th>\n",
       "      <td>Kreuzworträtsel F 10571</td>\n",
       "      <td>Täglich neu, exklusiv fürSmart-Abonnent:innen:...</td>\n",
       "      <td>https://www.derstandard.at/story/3000000199163...</td>\n",
       "      <td>2023-12-22T00:01</td>\n",
       "      <td>Kreuzworträtsel</td>\n",
       "      <td>4</td>\n",
       "      <td>Spiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182107 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0       Real Madrid stolpert mit Aluminiumpech im Tite...   \n",
       "1            Bolivien weist venezolanische Diplomaten aus   \n",
       "2       Erdoğan warnt vor neuer Flüchtlingswelle aus S...   \n",
       "3         Massenkarambolage mit 63 Fahrzeugen in Virginia   \n",
       "4       Salzburg schlägt Caps, Meister KAC mit vierter...   \n",
       "...                                                   ...   \n",
       "182102                            Wer braucht die Kirche?   \n",
       "182103  Sonderregelung verlängert: Mehr als 1.000 Ärzt...   \n",
       "182104  Stadtforscher: \"Architektur ist Teil unserer W...   \n",
       "182105  David Alaba zum zehnten Mal zu Österreichs Fuß...   \n",
       "182106                            Kreuzworträtsel F 10571   \n",
       "\n",
       "                                                 subtitle  \\\n",
       "0       Die Königlichen können Bilbao daheim nicht bes...   \n",
       "1       InterimspräsidentinJeanine Áñez wirft denBotsc...   \n",
       "2       Türkischer Präsident: \"80.000 Menschen Richtun...   \n",
       "3             Autos stießen auf vereister Brücke zusammen   \n",
       "4       Die Bullen sind damit der Gewinner der Runde: ...   \n",
       "...                                                   ...   \n",
       "182102  Dass sich die Kirche nach soschwerwiegendenVer...   \n",
       "182103  Der\"Pandemieparagraf\"im Ärztegesetz hat mehr a...   \n",
       "182104  Jetzt anhören: In Zukunft müssen Städte wieder...   \n",
       "182105  Zehn von zwölf Trainern wählten den derzeit ve...   \n",
       "182106  Täglich neu, exklusiv fürSmart-Abonnent:innen:...   \n",
       "\n",
       "                                                     link          datetime  \\\n",
       "0       https://www.derstandard.at/story/2000112599363...  2019-12-22T23:44   \n",
       "1       https://www.derstandard.at/story/2000112598924...  2019-12-22T22:50   \n",
       "2       https://www.derstandard.at/story/2000112598130...  2019-12-22T21:43   \n",
       "3       https://www.derstandard.at/story/2000112597972...  2019-12-22T21:29   \n",
       "4       https://www.derstandard.at/story/2000112595206...  2019-12-22T20:54   \n",
       "...                                                   ...               ...   \n",
       "182102  https://www.derstandard.at/story/3000000200743...  2023-12-22T06:00   \n",
       "182103  https://www.derstandard.at/story/3000000200621...  2023-12-22T06:00   \n",
       "182104  https://www.derstandard.at/story/3000000200499...  2023-12-22T06:00   \n",
       "182105  https://www.derstandard.at/story/3000000200745...  2023-12-22T05:46   \n",
       "182106  https://www.derstandard.at/story/3000000199163...  2023-12-22T00:01   \n",
       "\n",
       "                    kicker  n_posts storylabels  \n",
       "0         Primera Division       30         NaN  \n",
       "1       Übergangsregierung       16         NaN  \n",
       "2              Bürgerkrieg      104         NaN  \n",
       "3        Weihnachtsverkehr       35         NaN  \n",
       "4                Eishockey        4         NaN  \n",
       "...                    ...      ...         ...  \n",
       "182102      Dominik Straub        1   Kommentar  \n",
       "182103    Pandemieparagraf      148         NaN  \n",
       "182104     Edition Zukunft       54     Podcast  \n",
       "182105             Fußball       34         NaN  \n",
       "182106     Kreuzworträtsel        4       Spiel  \n",
       "\n",
       "[182107 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data loading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "standard_data = pd.read_csv('./data/4yrs_derstandard_frontpage_data.csv')\n",
    "standard_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing + lemmatizing, embeddings\n",
    "\n",
    "First, title and subtitile columns are split into individual words. Second, words are replaced by their standard forms (großem - groß, rettete - retten). Finally, the standard forms are converted to numeric vectors using toc2vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.tok2vec.Tok2Vec at 0x17e1a8cbcb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing two columns\n",
    "standard_data['title_tokens'] = standard_data['title']\n",
    "standard_data['subtitle_tokens'] = standard_data['subtitle']\n",
    "\n",
    "standard_data['title_vectors'] = standard_data['title_tokens']\n",
    "standard_data['subtitle_vectors'] = standard_data['subtitle_tokens']\n",
    "\n",
    "# Load model\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "nlp.get_pipe('lemmatizer')\n",
    "nlp.get_pipe(\"tok2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through rows\n",
    "\n",
    "for index, row in standard_data.iterrows():\n",
    "    \n",
    "    # TITLE\n",
    "\n",
    "    text = nlp(row['title_tokens'].replace(\"-\", \" \").replace(\",\", \" \").replace(\": \", \" \"))\n",
    "\n",
    "    token_list = ' '.join([token.lemma_ for token in text]) # list of standardized tokens joined to a string\n",
    "\n",
    "    vector_list = [token.vector for token in nlp(token_list)] # list of numeric vectors\n",
    "\n",
    "    # store in the dataframe\n",
    "\n",
    "    standard_data.at[index, 'title_tokens'] = token_list \n",
    "    standard_data.at[index, 'title_vectors'] = vector_list \n",
    "\n",
    "    # SAME FOR SUBTITLE\n",
    "\n",
    "    # try except because subtitle is sometimes empty, then it would output error\n",
    "\n",
    "    try:\n",
    "\n",
    "        text = nlp(row['subtitle_tokens'])\n",
    "        token_list = ' '.join([token.lemma_ for token in text]) # list of standardized tokens joined to a string\n",
    "        vector_list = [token.vector for token in nlp(token_list)] # list of numeric vectors\n",
    "\n",
    "    except:\n",
    "        token_list = '' # if empty, token list empty\n",
    "        vector_list = []\n",
    "\n",
    "    standard_data.at[index, 'subtitle_tokens'] = token_list # store in the dataframe\n",
    "    standard_data.at[index, 'subtitle_vectors'] = vector_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>link</th>\n",
       "      <th>datetime</th>\n",
       "      <th>kicker</th>\n",
       "      <th>n_posts</th>\n",
       "      <th>storylabels</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>subtitle_tokens</th>\n",
       "      <th>title_vectors</th>\n",
       "      <th>subtitle_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real Madrid stolpert mit Aluminiumpech im Tite...</td>\n",
       "      <td>Die Königlichen können Bilbao daheim nicht bes...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112599363...</td>\n",
       "      <td>2019-12-22T23:44</td>\n",
       "      <td>Primera Division</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Madrid stolpern mit Aluminiumpech in Tite...</td>\n",
       "      <td>der Königlich können Bilbao daheim nicht besiegen</td>\n",
       "      <td>[[1.4714637, 2.1941755, 0.37696052, 0.46038526...</td>\n",
       "      <td>[[2.48862, 0.1332562, -1.0822431, -2.6994205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolivien weist venezolanische Diplomaten aus</td>\n",
       "      <td>InterimspräsidentinJeanine Áñez wirft denBotsc...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598924...</td>\n",
       "      <td>2019-12-22T22:50</td>\n",
       "      <td>Übergangsregierung</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bolivien weisen venezolanisch Diplomat aus</td>\n",
       "      <td>InterimspräsidentinJeanine Áñez werfen denBots...</td>\n",
       "      <td>[[-1.3009748, -0.9428248, -3.3170214, 2.703031...</td>\n",
       "      <td>[[1.1021554, 1.5151364, -0.9405582, -2.410718,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Erdoğan warnt vor neuer Flüchtlingswelle aus S...</td>\n",
       "      <td>Türkischer Präsident: \"80.000 Menschen Richtun...</td>\n",
       "      <td>https://www.derstandard.at/story/2000112598130...</td>\n",
       "      <td>2019-12-22T21:43</td>\n",
       "      <td>Bürgerkrieg</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erdoğan warnen vor neu Flüchtlingswelle aus Sy...</td>\n",
       "      <td>Türkischer Präsident -- -- 80.000 Mensch Richt...</td>\n",
       "      <td>[[-1.0778335, 0.5461743, 2.5889783, -1.2373338...</td>\n",
       "      <td>[[-0.37814975, -0.962201, 0.65647066, -5.07107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Massenkarambolage mit 63 Fahrzeugen in Virginia</td>\n",
       "      <td>Autos stießen auf vereister Brücke zusammen</td>\n",
       "      <td>https://www.derstandard.at/story/2000112597972...</td>\n",
       "      <td>2019-12-22T21:29</td>\n",
       "      <td>Weihnachtsverkehr</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massenkarambolage mit 63 Fahrzeug in Virginia</td>\n",
       "      <td>Auto stoßen auf vereist Brücke zusammen</td>\n",
       "      <td>[[0.4362324, 2.8947713, -4.595852, -0.09335708...</td>\n",
       "      <td>[[-4.584771, -1.4883125, 0.2176263, 4.631511, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Real Madrid stolpert mit Aluminiumpech im Tite...   \n",
       "1       Bolivien weist venezolanische Diplomaten aus   \n",
       "2  Erdoğan warnt vor neuer Flüchtlingswelle aus S...   \n",
       "3    Massenkarambolage mit 63 Fahrzeugen in Virginia   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  Die Königlichen können Bilbao daheim nicht bes...   \n",
       "1  InterimspräsidentinJeanine Áñez wirft denBotsc...   \n",
       "2  Türkischer Präsident: \"80.000 Menschen Richtun...   \n",
       "3        Autos stießen auf vereister Brücke zusammen   \n",
       "\n",
       "                                                link          datetime  \\\n",
       "0  https://www.derstandard.at/story/2000112599363...  2019-12-22T23:44   \n",
       "1  https://www.derstandard.at/story/2000112598924...  2019-12-22T22:50   \n",
       "2  https://www.derstandard.at/story/2000112598130...  2019-12-22T21:43   \n",
       "3  https://www.derstandard.at/story/2000112597972...  2019-12-22T21:29   \n",
       "\n",
       "               kicker  n_posts storylabels  \\\n",
       "0    Primera Division       30         NaN   \n",
       "1  Übergangsregierung       16         NaN   \n",
       "2         Bürgerkrieg      104         NaN   \n",
       "3   Weihnachtsverkehr       35         NaN   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  Real Madrid stolpern mit Aluminiumpech in Tite...   \n",
       "1         Bolivien weisen venezolanisch Diplomat aus   \n",
       "2  Erdoğan warnen vor neu Flüchtlingswelle aus Sy...   \n",
       "3      Massenkarambolage mit 63 Fahrzeug in Virginia   \n",
       "\n",
       "                                     subtitle_tokens  \\\n",
       "0  der Königlich können Bilbao daheim nicht besiegen   \n",
       "1  InterimspräsidentinJeanine Áñez werfen denBots...   \n",
       "2  Türkischer Präsident -- -- 80.000 Mensch Richt...   \n",
       "3            Auto stoßen auf vereist Brücke zusammen   \n",
       "\n",
       "                                       title_vectors  \\\n",
       "0  [[1.4714637, 2.1941755, 0.37696052, 0.46038526...   \n",
       "1  [[-1.3009748, -0.9428248, -3.3170214, 2.703031...   \n",
       "2  [[-1.0778335, 0.5461743, 2.5889783, -1.2373338...   \n",
       "3  [[0.4362324, 2.8947713, -4.595852, -0.09335708...   \n",
       "\n",
       "                                    subtitle_vectors  \n",
       "0  [[2.48862, 0.1332562, -1.0822431, -2.6994205, ...  \n",
       "1  [[1.1021554, 1.5151364, -0.9405582, -2.410718,...  \n",
       "2  [[-0.37814975, -0.962201, 0.65647066, -5.07107...  \n",
       "3  [[-4.584771, -1.4883125, 0.2176263, 4.631511, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.1021554 ,  1.5151364 , -0.9405582 , -2.410718  , -1.1881657 ,\n",
       "        -3.615175  ,  1.0234319 ,  4.1538424 , -1.5936106 , -2.785506  ,\n",
       "         0.6842209 ,  0.07389921,  0.5360052 ,  0.31706142, -0.9196383 ,\n",
       "        -0.82573223, -3.5580513 , -1.8286765 ,  0.10499629, -2.6490862 ,\n",
       "         0.7699168 ,  0.9488483 ,  3.0474105 , -3.499149  , -1.3851355 ,\n",
       "        -1.3532616 , -2.1080291 ,  1.4907815 ,  1.6701344 ,  0.32809997,\n",
       "         3.3263462 ,  1.2118888 , -0.66293633, -0.6889895 , -0.9815758 ,\n",
       "         7.8648634 , -2.7158377 ,  1.1486918 ,  1.389757  ,  2.5390139 ,\n",
       "        -2.2970562 ,  1.9853625 , -0.53672844,  1.7880895 ,  1.0695057 ,\n",
       "        -1.396502  , -0.44181645,  8.145238  , -6.583647  ,  2.6661644 ,\n",
       "        -3.5900345 ,  5.988452  ,  0.7246865 ,  0.7114573 , -0.97419953,\n",
       "        -0.59691894, -1.2567514 ,  1.227717  , -0.20339483,  1.2106575 ,\n",
       "        -3.6484938 , -0.32804242, -0.22830245, -2.9978542 , -1.7434182 ,\n",
       "         1.2077783 ,  1.3858008 , -2.3194008 ,  2.691605  , -1.2882311 ,\n",
       "         0.36779276,  6.1339602 ,  5.0458665 ,  2.7170045 , -0.73983014,\n",
       "        -1.4936604 , -3.691854  , -0.58311963, -2.758136  ,  1.3663645 ,\n",
       "         0.7641036 , -0.25958115,  0.19299927, -0.36475182, -2.15046   ,\n",
       "        -0.07376699,  1.3615923 ,  0.15364465,  0.43697536, -0.7795961 ,\n",
       "        -0.2906142 , -1.3341428 , -1.1321028 ,  0.7692802 ,  4.4434543 ,\n",
       "        -0.13221759], dtype=float32),\n",
       " array([ 2.0387900e-01, -3.6389467e-01,  9.1594264e-02,  3.0110793e+00,\n",
       "         1.9099593e-01,  2.5002155e+00,  4.7174902e+00,  3.2845149e+00,\n",
       "         2.4571249e+00, -3.9303410e-01,  2.4632785e+00,  3.5243196e+00,\n",
       "         8.2635641e-02, -3.7615123e-01, -2.4238696e+00,  9.4931561e-01,\n",
       "        -3.1734276e+00, -3.2585377e-01, -9.5212698e-02, -3.6530802e+00,\n",
       "         2.6839254e+00,  3.8944585e+00,  2.8477988e+00,  9.7264910e-01,\n",
       "        -3.4695044e+00, -1.8469485e+00, -1.1298934e+00, -1.7287492e+00,\n",
       "        -1.7891788e+00, -1.2972705e+00, -4.0097499e+00, -1.6719009e+00,\n",
       "        -2.6558471e-01,  4.8970847e+00, -1.6694819e+00,  2.8998227e+00,\n",
       "         3.6650777e-02,  2.3830295e-02, -4.0626961e-01, -1.1825575e+00,\n",
       "         4.5469692e-01,  7.1066767e-02,  1.1704326e-01,  2.2460222e+00,\n",
       "        -2.2601731e+00, -2.4881077e-01,  5.1106195e+00, -7.0074636e-01,\n",
       "         2.4542422e+00,  4.2827673e+00, -3.7211795e+00,  4.0359521e+00,\n",
       "         1.0617015e+00, -1.5808861e+00,  2.8038654e+00,  2.0369215e+00,\n",
       "        -2.3406210e+00,  1.6063156e+00,  1.2375314e+00, -3.9418101e+00,\n",
       "        -3.1209874e+00,  5.3786767e-01, -7.0941699e-01, -8.3923918e-01,\n",
       "         1.9914703e+00, -5.0472933e-01,  1.6171703e+00, -2.4083114e+00,\n",
       "         1.1187898e+00,  1.1807323e+00,  3.7856526e+00, -3.2749174e+00,\n",
       "         5.1386099e+00,  1.0498765e+00, -2.7171969e-03, -2.5394652e+00,\n",
       "        -1.9865291e+00, -2.3191524e+00, -3.2128429e-01, -2.3197007e+00,\n",
       "        -7.2254086e-01, -1.9952973e+00, -1.2792372e+00, -2.8368850e+00,\n",
       "        -2.9223857e+00, -5.3396523e-01, -2.3760524e+00, -9.1870689e-01,\n",
       "        -2.1093471e+00,  3.1699508e-01, -1.6469510e+00, -1.2593009e+00,\n",
       "         2.1777494e-01,  4.9522644e-01,  1.0336641e+00,  2.7116790e-01],\n",
       "       dtype=float32),\n",
       " array([-0.83021116,  1.497284  , -0.9227109 ,  1.802495  ,  2.49502   ,\n",
       "         0.3021891 ,  1.4051473 ,  4.7342453 , -1.3231409 ,  0.7152008 ,\n",
       "         1.3497535 , -0.68772495, -1.1351818 , -2.8685963 ,  0.19471988,\n",
       "         1.866097  , -0.659291  , -2.4652512 , -3.6585813 , -1.970429  ,\n",
       "         0.6091137 , -0.5410261 , -1.093161  , -0.93193674, -2.1877618 ,\n",
       "        -0.34253335,  4.331459  ,  2.406736  , -1.5875481 , -1.2403198 ,\n",
       "         0.3342938 ,  0.8339085 , -1.4179932 ,  2.086682  , -0.2932942 ,\n",
       "         0.7463709 ,  1.54034   , -2.472604  , 10.581617  ,  1.2359589 ,\n",
       "        -1.5131515 ,  5.729193  ,  3.1587148 , -2.8493028 ,  0.4284364 ,\n",
       "        -1.7156467 , -1.3902086 , -0.8821014 ,  1.0003353 , -0.22503006,\n",
       "        -3.058124  ,  1.2050474 ,  0.63327134, -3.7192645 ,  1.9260386 ,\n",
       "         1.5659823 , -0.15807867,  0.9381081 , -2.2680752 ,  2.4811857 ,\n",
       "         0.6327281 ,  2.806039  , -0.7336584 , -2.7372947 ,  1.6763592 ,\n",
       "        -2.0626225 , -1.2927849 , -3.0047374 ,  2.9425187 ,  2.2545786 ,\n",
       "        -5.1119127 ,  1.6616504 , -1.0005181 ,  0.44565445, -1.792507  ,\n",
       "         1.9223206 , -1.522932  ,  1.6897063 , -0.14903557, -0.6437911 ,\n",
       "        -3.3589764 , -1.3296492 ,  1.4645389 , -0.55227613,  0.96184725,\n",
       "         4.250011  ,  0.8981428 , -3.2711775 ,  0.94647956, -2.0579686 ,\n",
       "        -0.07125318, -1.0319518 ,  1.4655437 ,  0.73916465, -2.4736276 ,\n",
       "        -2.4883735 ], dtype=float32),\n",
       " array([ 0.4268612 ,  0.11444321, -3.5183058 , -0.4342844 ,  0.51640785,\n",
       "        -1.5647693 ,  2.8943887 ,  1.4340794 , -2.0140646 , -1.3430088 ,\n",
       "        -0.60300016,  0.67714226,  0.73942363,  1.4505097 , -3.9787164 ,\n",
       "        -1.6661923 ,  1.1756002 , -0.01579541, -1.4690632 , -4.521759  ,\n",
       "         2.9466097 ,  0.6662991 ,  1.0837626 ,  3.397083  , -0.5540648 ,\n",
       "        -0.9863453 ,  2.3200371 , -1.8510854 ,  1.4576211 , -0.9045007 ,\n",
       "         0.96012497,  3.4490943 ,  3.8648047 , -0.08552533,  0.7867209 ,\n",
       "        -0.08240172,  1.1028842 , -0.6129677 ,  0.56159705,  1.0788395 ,\n",
       "         1.9978597 ,  0.7594922 , -0.02069485, -0.19586757,  3.6035194 ,\n",
       "         2.6952    , -2.8366916 ,  1.1927326 ,  0.09903134, -3.0415542 ,\n",
       "        -3.2372315 ,  2.9434052 ,  2.5885506 ,  3.2774305 ,  4.2413726 ,\n",
       "        -3.212422  ,  3.0751781 ,  2.4350133 , -0.49164814,  0.11654021,\n",
       "         4.640836  , -1.9098933 ,  0.22600174, -3.6791887 , -0.14912975,\n",
       "         1.8631192 , -2.7025967 , -1.8053133 , -2.6565313 , -0.6381764 ,\n",
       "        -0.61491895, -1.0311294 , -1.1377723 ,  3.2797484 , -2.7812965 ,\n",
       "        -0.1707015 , -2.4011383 , -0.63554215, -2.9577036 , -2.9310107 ,\n",
       "        -0.5228375 ,  0.47581732, -0.25083572,  1.7707635 , -0.58195096,\n",
       "         1.2655902 , -0.68389213,  0.69857156, -2.7911675 ,  0.70694065,\n",
       "        -3.957206  , -0.22527076,  3.1920824 , -1.3613758 ,  1.5655717 ,\n",
       "        -1.1629789 ], dtype=float32),\n",
       " array([ 2.858104  , -0.4259818 ,  0.0533731 , -3.2954707 , -0.14817905,\n",
       "         0.05753967,  1.0969156 , -0.34743267,  0.88959074,  0.5335532 ,\n",
       "         1.0946918 , -2.226666  ,  0.514783  ,  0.73557144, -1.1123455 ,\n",
       "         2.187058  ,  0.50760436, -0.5147372 ,  1.2438729 , -0.04412994,\n",
       "         0.05263746,  1.4446843 ,  0.2778504 ,  1.341911  , -3.6685023 ,\n",
       "         0.9865285 ,  1.3624797 , -0.0123758 , -2.691949  ,  4.033491  ,\n",
       "        -0.56697977,  0.4989763 , -0.21788037,  4.2447743 , -1.2398992 ,\n",
       "         1.0839074 , -2.477867  , -1.7621161 ,  1.8945113 ,  2.3866873 ,\n",
       "        -2.59024   , -0.96871006, -0.33251345, -0.12506872,  4.552087  ,\n",
       "         2.8513644 ,  0.41111633,  0.51917094,  0.02366787, -0.5274012 ,\n",
       "        -2.7292676 , -2.0452867 ,  4.2623873 ,  0.3875122 , -0.8248315 ,\n",
       "        -0.32203722, -1.1037903 , -3.0828161 ,  2.2062783 , -2.6692753 ,\n",
       "        -2.0157883 , -1.058212  ,  1.3724246 , -1.9377549 , -2.2691765 ,\n",
       "        -0.9465351 , -0.53197896, -1.8847213 , -3.646227  ,  2.8391743 ,\n",
       "        -1.6809651 , -0.92708457, -1.2322042 ,  1.6195769 , -0.23415822,\n",
       "         2.8377922 , -1.9586563 , -1.9909892 , -2.0246377 , -2.9430902 ,\n",
       "        -1.6619481 ,  1.4801362 , -0.16447723,  1.5505334 ,  0.4808987 ,\n",
       "         4.3188734 ,  0.46803015, -0.8805185 ,  0.80877286,  2.0628033 ,\n",
       "         1.3530104 ,  3.0936437 ,  0.5739267 ,  1.0531263 , -2.2153168 ,\n",
       "         1.1867065 ], dtype=float32),\n",
       " array([-3.8055253 , -3.5115027 , -1.0059981 , -3.6148624 , -0.45541   ,\n",
       "         2.3010263 , -3.123283  ,  3.9836278 ,  3.305799  ,  3.148072  ,\n",
       "        -1.4811625 , -3.2537093 , -2.457415  ,  1.2686638 , -0.13613607,\n",
       "         2.6724596 ,  1.2367618 ,  3.622371  ,  3.260768  , -1.2518926 ,\n",
       "        -1.6727774 ,  3.5320773 , -1.8793987 ,  1.3768798 , -2.7413633 ,\n",
       "        -0.6037619 , -0.06114875, -0.48323965,  0.9015295 ,  2.0272603 ,\n",
       "        -2.2566009 ,  0.5120633 , -1.2588562 ,  1.9404176 ,  3.8674512 ,\n",
       "        -0.04215217, -2.9890358 ,  2.0556245 ,  0.22212723,  1.749618  ,\n",
       "         0.33235598,  0.03336096,  1.8797287 ,  4.888695  , -0.01029098,\n",
       "        -1.3796326 ,  1.8553174 , -1.8387939 , -1.1648893 ,  1.3825982 ,\n",
       "        -2.707078  ,  3.1952686 ,  2.238944  , -2.453817  ,  1.5905297 ,\n",
       "        -0.2021507 , -0.10128054, -1.0571215 ,  2.0745199 , -1.4071221 ,\n",
       "        -3.8053017 ,  0.4611584 , -2.3974686 , -1.6399364 ,  2.0876296 ,\n",
       "         0.16720504,  2.3801744 ,  1.154994  , -2.763418  , -0.97302604,\n",
       "         3.1014602 , -1.7898778 ,  4.876471  , -2.9201698 ,  2.3444037 ,\n",
       "        -4.772825  , -2.9049087 , -1.5523417 , -4.17309   ,  1.2448903 ,\n",
       "        -1.6100448 ,  0.65438884, -0.91534674, -1.5658777 ,  1.8594563 ,\n",
       "         0.8504069 , -1.5365098 ,  2.7906036 ,  0.7174556 , -0.85909116,\n",
       "         2.2371955 ,  2.434044  , -1.1921433 , -0.3468234 ,  1.2002109 ,\n",
       "        -2.4800344 ], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of list of numeric vectors representing a subtitle\n",
    "\n",
    "standard_data.iloc[1,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining predictors and dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sum vectors for words  to get a vector for a sentence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "standard_data_copy = standard_data.copy()\n",
    "\n",
    "for index,row in standard_data_copy.iterrows():\n",
    "\n",
    "    l = standard_data_copy.loc[index, 'title_vectors']\n",
    "    standard_data_copy.at[index, 'title_vectors'] = np.sum(l, axis=0)\n",
    "\n",
    "    l = standard_data_copy.loc[index, 'subtitle_vectors']\n",
    "    standard_data_copy.at[index, 'subtitle_vectors'] = np.sum(l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.119195  ,   0.4420882 ,  -6.585746  ,  -0.36528832,\n",
       "          5.3427124 ,   8.7853775 ,  -5.9323215 ,  15.100472  ,\n",
       "          8.413376  ,   0.498165  ,  15.515087  , -10.902954  ,\n",
       "        -14.050985  ,   6.649028  , -11.754989  ,   6.057748  ,\n",
       "          8.1888    ,  -2.3931763 ,  -3.9362216 ,  -2.4156115 ,\n",
       "          1.1384144 ,  16.5233    ,  -3.1429567 ,  12.609358  ,\n",
       "        -10.458169  , -14.882816  ,  -7.4182734 ,   2.4116597 ,\n",
       "         -5.4921722 ,   7.045065  , -10.576113  ,  -2.9996653 ,\n",
       "         -2.5590808 ,  15.348734  ,  17.18261   ,   6.2615204 ,\n",
       "          1.5978868 ,   4.3599935 ,   6.792941  ,   0.34123358,\n",
       "         -4.33022   ,   1.9403619 ,  -4.0108805 ,  -3.0241973 ,\n",
       "          2.9737525 ,   5.95477   ,  -1.0211641 ,  -9.582537  ,\n",
       "         16.537086  ,  -1.5229907 , -17.975307  ,  14.044141  ,\n",
       "         17.179005  , -15.048843  ,  -3.5073388 ,  -9.0553465 ,\n",
       "          7.744524  ,  -1.2955302 ,  -1.1938403 ,  -0.9916693 ,\n",
       "         -5.2311893 , -15.524109  ,  -1.8139477 ,  -5.236508  ,\n",
       "         -7.388012  ,   1.6616129 ,   9.769495  ,  -3.0856996 ,\n",
       "          5.103663  , -10.281055  ,  -8.181546  ,  11.605755  ,\n",
       "         20.072994  ,   1.9509575 ,   1.0104284 ,   2.7451582 ,\n",
       "         -6.7651024 , -17.938444  ,  -0.29718518,  -4.189915  ,\n",
       "          0.49740887,  -1.7963977 ,   1.3374608 ,   3.804048  ,\n",
       "          0.82973343,  -4.5802813 ,  -3.792004  ,   0.59529376,\n",
       "         -4.4479127 ,   3.0961576 ,   0.09678364,   6.9876165 ,\n",
       "          3.4458823 ,   5.249668  ,  -5.503358  ,   2.4459732 ],\n",
       "       [  4.1763725 ,   6.6053157 ,  -6.26212   ,  -1.8468281 ,\n",
       "          5.8947444 , -11.055052  ,  16.409658  ,   4.4481072 ,\n",
       "         10.801826  ,   2.6705813 ,  19.742989  , -10.982428  ,\n",
       "         -7.0191803 ,   1.378798  ,  -2.3377242 ,   3.6979463 ,\n",
       "          0.8893782 ,  -0.24522638,  -2.0405407 ,   7.9179482 ,\n",
       "         -7.7598577 ,   5.657601  ,   8.710294  ,   7.591489  ,\n",
       "         -7.517646  ,  -9.373699  ,  12.201945  ,   1.6120387 ,\n",
       "         -4.4405456 ,   2.064506  ,  -4.025571  ,  -1.2569398 ,\n",
       "          9.275347  ,   3.774525  ,  -2.4166684 ,   5.925064  ,\n",
       "         -4.9106    ,   6.250013  ,   3.1558099 ,   5.1071405 ,\n",
       "          0.76229167,  12.146876  ,  -2.4513674 ,  -0.679394  ,\n",
       "         -1.4179453 ,   2.5416732 ,  -4.7745566 ,  -8.512492  ,\n",
       "          4.8051677 ,  -6.053112  , -11.54631   ,   0.36491406,\n",
       "          0.8190367 ,  -6.9885855 ,  -1.56673   ,  -4.1197243 ,\n",
       "          2.7763567 ,   5.4589043 ,  -1.6369283 ,  -1.204077  ,\n",
       "         -4.955944  ,  -0.5450032 , -10.904157  ,  -0.17724037,\n",
       "         -5.962854  ,   4.716673  ,  -0.22160816,  -7.6610374 ,\n",
       "         -6.0942597 ,   5.3322835 ,  -3.6568193 ,  -4.372014  ,\n",
       "          9.467594  ,   1.2784152 ,  -5.0787563 ,   1.5037313 ,\n",
       "         -7.411691  ,  -7.2856708 ,   3.2065206 ,  -6.4576864 ,\n",
       "         -3.1081047 ,  -3.3992252 ,  -0.32932377,   0.11005902,\n",
       "         -2.4886897 ,   9.941364  ,   6.774614  ,  -4.425606  ,\n",
       "         -0.5213309 ,   3.925714  ,   4.3876085 ,   0.7395493 ,\n",
       "          1.7669291 ,   6.883208  ,  -5.6511483 ,  -1.0476801 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping\n",
    "\n",
    "X = np.vstack(standard_data_copy['title_vectors'].to_numpy())\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182107, 1)\n",
      "(182107, 96)\n"
     ]
    }
   ],
   "source": [
    "# split y to above and under 50 posts (regression -> classification)\n",
    "\n",
    "y = (standard_data_copy['n_posts'].to_numpy() > 50).astype(int)\n",
    "y = np.column_stack(standard_data_copy['n_posts'].to_numpy() > 50).astype(int).T\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42069)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two hidden layers, each with 12 nodes\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs = 96):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(n_inputs, 12)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(12, 12)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(12, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "    \n",
    "loss_fn = nn.L1Loss(size_average=None, reduce=None, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "import random\n",
    "\n",
    "def train_binary_model(X_train, Y_train, n_inputs = 96, n_epochs = 5000):\n",
    "\n",
    "    model = BinaryClassifier(n_inputs)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    random.seed(42069)\n",
    "    batch_size = int(len(X_train) / 50)\n",
    "    print(batch_size)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            Xbatch = X_train[i:i+batch_size]\n",
    "            y_pred = model(Xbatch)\n",
    "            ybatch = Y_train[i:i+batch_size]\n",
    "            loss = loss_fn(y_pred, ybatch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            baseline = sum(ybatch) / len(ybatch)\n",
    "            accuracy = sum(ybatch == y_pred.round())/len(ybatch)\n",
    "            print(f'Finished epoch {epoch}, latest loss {loss}, accuracy {accuracy} vs baseline {baseline}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "\n",
    "def test_binary_model(model, X_test):\n",
    "    Y_hat = model(X_test).round()\n",
    "    print(\"Accuracy: \")\n",
    "    print((sum(Y_test == Y_hat)/len(Y_test)).item())\n",
    "    print(\"Baseline accuracy: \")\n",
    "    print((sum(Y_test)/len(Y_test)).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2913\n",
      "Finished epoch 0, latest loss 0.28019288182258606, accuracy tensor([0.7143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 100, latest loss 0.11489197611808777, accuracy tensor([0.8857]) vs baseline tensor([0.6000])\n",
      "Finished epoch 200, latest loss 0.08579690009355545, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 300, latest loss 0.08585256338119507, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 400, latest loss 0.08591507375240326, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 500, latest loss 0.08572710305452347, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 600, latest loss 0.08575011789798737, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 700, latest loss 0.08571437746286392, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 800, latest loss 0.08571577072143555, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 900, latest loss 0.08582895994186401, accuracy tensor([0.9143]) vs baseline tensor([0.6000])\n"
     ]
    }
   ],
   "source": [
    "model = train_binary_model(X_train, Y_train, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.6365109086036682\n",
      "Baseline accuracy: \n",
      "0.5655098557472229\n"
     ]
    }
   ],
   "source": [
    "test_binary_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we get better accuracy using subtitles?\n",
    "\n",
    "Here, we try using subtitle instead of article title as the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(standard_data_copy)):\n",
    "\n",
    "    if standard_data_copy.loc[i, 'subtitle_tokens'] == '':\n",
    "        standard_data_copy.at[i, 'subtitle_vectors'] = np.zeros(96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(standard_data_copy['subtitle_vectors'].to_numpy())\n",
    "X\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42069)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2913\n",
      "Finished epoch 0, latest loss 0.368115097284317, accuracy tensor([0.6571]) vs baseline tensor([0.6000])\n",
      "Finished epoch 100, latest loss 0.20157773792743683, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 200, latest loss 0.2004449963569641, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 300, latest loss 0.20048309862613678, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 400, latest loss 0.20007279515266418, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 500, latest loss 0.20005889236927032, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 600, latest loss 0.20005641877651215, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 700, latest loss 0.2000395506620407, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 800, latest loss 0.20004263520240784, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 900, latest loss 0.20002888143062592, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n"
     ]
    }
   ],
   "source": [
    "model = train_binary_model(X_train, Y_train, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.6548514366149902\n",
      "Baseline accuracy: \n",
      "0.5655098557472229\n"
     ]
    }
   ],
   "source": [
    "test_binary_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, using article's subtitle yields worse imporvement in accuracy. Next, we try using both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182107, 192)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((np.vstack(standard_data_copy['title_vectors'].to_numpy()), np.vstack(standard_data_copy['subtitle_vectors'].to_numpy())), axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42069)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2913\n",
      "Finished epoch 0, latest loss 0.29562562704086304, accuracy tensor([0.7143]) vs baseline tensor([0.6000])\n",
      "Finished epoch 100, latest loss 0.20029419660568237, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 200, latest loss 0.20000003278255463, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 300, latest loss 0.2000010460615158, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 400, latest loss 0.2000003308057785, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 500, latest loss 0.20000004768371582, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 600, latest loss 0.20000001788139343, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 700, latest loss 0.20000068843364716, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 800, latest loss 0.20000000298023224, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n",
      "Finished epoch 900, latest loss 0.20000000298023224, accuracy tensor([0.8000]) vs baseline tensor([0.6000])\n"
     ]
    }
   ],
   "source": [
    "model = train_binary_model(X_train, Y_train, n_inputs = 192, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.6726703643798828\n",
      "Baseline accuracy: \n",
      "0.5655098557472229\n"
     ]
    }
   ],
   "source": [
    "test_binary_model(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Multi-class classifier\n",
    "\n",
    "We also want to try out a classifier for variables with more than two categories. The predictors are going to be the same, for dependent variables we will choose columns *kicker* and *storylabels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Kickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kicker\n",
       "Fußball                 3162\n",
       "Nachrichtenüberblick    3101\n",
       "Netzpolitik             2674\n",
       "Sudoku                  2414\n",
       "Bundesliga              1775\n",
       "Sport                   1684\n",
       "USA                     1518\n",
       "IT-Business             1464\n",
       "Coronavirus             1464\n",
       "Games                   1356\n",
       "Tennis                  1252\n",
       "Switchlist              1208\n",
       "Krieg in der Ukraine    1203\n",
       "Deutsche Bundesliga     1180\n",
       "Etat-Überblick          1161\n",
       "Hans Rauscher           1153\n",
       "Wintersport             1134\n",
       "TV-Tagebuch             1080\n",
       "Eishockey               1058\n",
       "Thema des Tages         1032\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 most common kickers\n",
    "\n",
    "standard_data_copy['kicker'].value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kicker</th>\n",
       "      <th>title_vectors</th>\n",
       "      <th>subtitle_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eishockey</td>\n",
       "      <td>[16.587378, -5.880515, -10.134394, -2.7442758,...</td>\n",
       "      <td>[17.787502, -9.519611, 6.9725924, -22.601917, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deutsche Bundesliga</td>\n",
       "      <td>[5.977871, -8.565644, -8.99353, 8.525143, 13.7...</td>\n",
       "      <td>[30.480652, -4.33595, -10.554278, -1.181915, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sport</td>\n",
       "      <td>[6.727174, -2.1885931, -6.3502436, -9.411136, ...</td>\n",
       "      <td>[4.372181, -6.303278, -5.9711304, 3.729673, 8....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                kicker                                      title_vectors  \\\n",
       "0            Eishockey  [16.587378, -5.880515, -10.134394, -2.7442758,...   \n",
       "1  Deutsche Bundesliga  [5.977871, -8.565644, -8.99353, 8.525143, 13.7...   \n",
       "2                Sport  [6.727174, -2.1885931, -6.3502436, -9.411136, ...   \n",
       "\n",
       "                                    subtitle_vectors  \n",
       "0  [17.787502, -9.519611, 6.9725924, -22.601917, ...  \n",
       "1  [30.480652, -4.33595, -10.554278, -1.181915, 1...  \n",
       "2  [4.372181, -6.303278, -5.9711304, 3.729673, 8....  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering for the most common ones\n",
    "\n",
    "kickers_20 = standard_data_copy['kicker'].value_counts().nlargest(20).index.tolist()\n",
    "\n",
    "standard_kickers = standard_data_copy.copy()\n",
    "standard_kickers = standard_kickers[standard_kickers['kicker'].isin(kickers_20)].reset_index()[['kicker', 'title_vectors', 'subtitle_vectors']]\n",
    "\n",
    "standard_kickers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent variable: bianry vector of length 20\n",
    "\n",
    "y = np.zeros((len(standard_kickers), 20))\n",
    "y.shape\n",
    "\n",
    "for row in range(y.shape[0]):\n",
    "    y_row = [1 if k == standard_kickers['kicker'][row] else 0 for k in kickers_20]\n",
    "    y[row,] = y_row\n",
    "\n",
    "y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.78750229,  -9.51961136,   6.97259235, -22.60191727,\n",
       "         23.74225616,   9.31873894,   8.5572834 ,  23.8451519 ,\n",
       "         10.47311592,   0.22695971,  34.2782402 , -30.66071892,\n",
       "        -22.11200523,  -2.05303741, -20.84233093,  24.89317513,\n",
       "         20.07475853,  42.06415558, -25.77451897,  -8.23214912,\n",
       "         23.6224556 ,  20.40205765,  24.19214058,   2.76441216,\n",
       "        -18.69178772, -16.48721504,  19.79255867,  -3.66987586,\n",
       "         40.11144257,  12.80308914, -32.58789825,  -8.74606419,\n",
       "          4.88409948,   1.47553456,  16.15632629, -12.9812727 ,\n",
       "          1.87224245,  -2.28196573,  20.60498428,   2.65613198,\n",
       "        -31.96606445,  53.01169968,  10.38889885,  -8.28358364,\n",
       "         42.46792603,   4.36738205, -20.69274902, -27.77854729,\n",
       "        -12.88485432,  -8.18120575, -25.95684433,  11.9279747 ,\n",
       "         -2.15959144,   5.14111853,  18.90647316, -12.25464344,\n",
       "         20.79118919,  24.50359917, -17.3789978 , -15.80044937,\n",
       "        -12.89952755, -20.38439178,  -5.98169279,   1.39122534,\n",
       "        -20.21481514,   1.05093873,  16.25543022, -30.86683083,\n",
       "          2.52105093,  18.34233665, -33.49952698,  25.06282616,\n",
       "         47.10434723, -23.10667419, -39.30410767, -18.42495155,\n",
       "         -8.50583649,  -4.53000689,  13.55102825, -21.09018326,\n",
       "        -14.89650345,  -8.21998405, -23.88335419,  19.44838142,\n",
       "         -3.64663601,  14.58350945, -11.82317543,  13.01065826,\n",
       "          1.91321766,  23.72675323,  21.42988396,  35.87226486,\n",
       "         12.88493824,   7.5420599 , -20.29470253,  20.51945877],\n",
       "       [ 30.48065186,  -4.3359499 , -10.55427837,  -1.18191504,\n",
       "         18.83841705,  17.63163757,  30.53222275,  20.03815842,\n",
       "          3.39736319,   2.30487394,  25.3445015 ,  -7.26597357,\n",
       "         -4.58202076, -14.59606552, -19.73396683,   9.31867218,\n",
       "         -9.59283638,  21.59188461,   1.12145662,   1.50997066,\n",
       "         23.1015892 ,  33.62531281,  17.11453629,  19.28170586,\n",
       "        -13.00364304, -14.07565594,   2.0197711 , -16.49940872,\n",
       "         11.45446682,   6.29826355, -22.30833817,  -0.72283781,\n",
       "         15.60744572,  19.16539383,  16.84324837,  -3.12985754,\n",
       "          1.29834294,   8.66239357,  35.42202377,  -7.05598974,\n",
       "        -29.72544479,  30.3167038 ,   4.89661646,   9.35298061,\n",
       "         19.87916946,  16.34698486, -11.17651176, -14.47218132,\n",
       "         16.27173615,  12.55965996, -38.4762001 ,  18.57327461,\n",
       "         11.58078003, -18.65499115,  15.47526932, -11.61715317,\n",
       "         13.75895691,  15.42659092,   5.01880741, -11.45995712,\n",
       "        -21.76966667, -25.96429634, -25.58132172, -41.12456894,\n",
       "         -3.47233582,   7.15661573,  18.72220612, -31.13856506,\n",
       "          6.04983616,  -4.88566685,  -3.87553883,  18.30246544,\n",
       "         28.63316536,  -4.63203001,  -3.52348185,  -9.22648239,\n",
       "        -33.90135574, -24.38999176,   7.14297867, -12.18540764,\n",
       "        -31.93712425,  -0.31258076,  -1.26990783,   0.40502286,\n",
       "          4.4830904 ,  10.65467453,  -2.97914696,  -4.40925884,\n",
       "        -21.99129105,   7.50469494,  13.47981453,  -5.81780672,\n",
       "         -1.40452564,   1.18488801, -13.77711582,  -2.79524326]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_title = np.vstack(standard_kickers['title_vectors'].to_numpy())\n",
    "X_title[0:2]\n",
    "\n",
    "X_subtitle = np.vstack(standard_kickers['subtitle_vectors'].to_numpy())\n",
    "X_subtitle[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_train, X_title_test, Y_train, Y_test = train_test_split(X_title, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subtitle_train, X_subtitle_test, Y_train, Y_test = train_test_split(X_subtitle, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_train = torch.tensor(X_title_train, dtype=torch.float32)\n",
    "X_title_test = torch.tensor(X_title_test, dtype=torch.float32)\n",
    "\n",
    "X_subtitle_train = torch.tensor(X_subtitle_train, dtype=torch.float32)\n",
    "X_subtitle_test = torch.tensor(X_subtitle_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTwentyCategories(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(n_inputs, 48)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(48, 24)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(24, 20)\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiclass_model(X_train, Y_train, n_inputs = 96, n_epochs = 1000):\n",
    "\n",
    "    random.seed(42069)\n",
    "\n",
    "    model = ClassifierTwentyCategories(n_inputs)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    batch_size = int(len(X_train) / 19)\n",
    "    print(batch_size)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            Xbatch = X_train[i:i+batch_size]\n",
    "            y_pred = model(Xbatch)\n",
    "            ybatch = Y_train[i:i+batch_size]\n",
    "            loss = loss_fn(y_pred, ybatch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            y_pred_category = [torch.argmax(r).item() for r in y_pred]\n",
    "            ybatch_category = [torch.argmax(r).item() for r in ybatch]\n",
    "            accuracy = sum([1 if x == y else 0 for x, y in zip(y_pred_category, ybatch_category)]) / len(ybatch_category)\n",
    "            print(f'Finished epoch {epoch}, latest loss {loss}, accuracy {accuracy}')\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiclass_model(model, X_test, Y_test, categories = kickers_20):\n",
    "    \n",
    "    p = [torch.argmax(r).item() for r in model(X_test)] \n",
    "    Y_hat = [categories[i] for i in p]\n",
    "\n",
    "    p = [torch.argmax(r).item() for r in Y_test] \n",
    "\n",
    "    Y_test_values = [categories[i] for i in p]\n",
    "\n",
    "    acc = sum([1 if x == y else 0 for x, y in zip(Y_hat, Y_test_values)]) / len(Y_test_values)\n",
    "    print(\"Accuracy: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266\n",
      "Finished epoch 0, latest loss 2.870898723602295, accuracy 0.23617693522906794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 100, latest loss 2.3970587253570557, accuracy 0.4794628751974723\n",
      "Finished epoch 200, latest loss 2.3890132904052734, accuracy 0.466824644549763\n",
      "Finished epoch 300, latest loss 2.3703079223632812, accuracy 0.4565560821484992\n",
      "Finished epoch 400, latest loss 2.3584561347961426, accuracy 0.4565560821484992\n",
      "Finished epoch 500, latest loss 2.347475528717041, accuracy 0.45734597156398105\n",
      "Finished epoch 600, latest loss 2.3382813930511475, accuracy 0.4510268562401264\n",
      "Finished epoch 700, latest loss 2.338529348373413, accuracy 0.4518167456556082\n",
      "Finished epoch 800, latest loss 2.335376024246216, accuracy 0.44944707740916273\n",
      "Finished epoch 900, latest loss 2.3318440914154053, accuracy 0.4565560821484992\n"
     ]
    }
   ],
   "source": [
    "model_titles = train_multiclass_model(X_title_train, Y_train, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.409652076318743\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(model_titles, X_title_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266\n",
      "Finished epoch 0, latest loss 2.843013048171997, accuracy 0.06398104265402843\n",
      "Finished epoch 100, latest loss 2.4316508769989014, accuracy 0.4146919431279621\n",
      "Finished epoch 200, latest loss 2.4045395851135254, accuracy 0.4028436018957346\n",
      "Finished epoch 300, latest loss 2.3934378623962402, accuracy 0.39257503949447076\n",
      "Finished epoch 400, latest loss 2.39837384223938, accuracy 0.39968404423380727\n",
      "Finished epoch 500, latest loss 2.4003560543060303, accuracy 0.38704581358609796\n",
      "Finished epoch 600, latest loss 2.383061170578003, accuracy 0.3941548183254344\n",
      "Finished epoch 700, latest loss 2.377591609954834, accuracy 0.3902053712480253\n",
      "Finished epoch 800, latest loss 2.364919662475586, accuracy 0.4028436018957346\n",
      "Finished epoch 900, latest loss 2.372812271118164, accuracy 0.3933649289099526\n"
     ]
    }
   ],
   "source": [
    "model_subtitles = train_multiclass_model(X_subtitle_train, Y_train, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3559047262750967\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(model_subtitles, X_subtitle_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32073, 192)\n",
      "(32073, 20)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((np.vstack(standard_kickers['title_vectors'].to_numpy()), np.vstack(standard_kickers['subtitle_vectors'].to_numpy())), axis=1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266\n",
      "Finished epoch 0, latest loss 2.7735064029693604, accuracy 0.2401263823064771\n",
      "Finished epoch 100, latest loss 2.3024654388427734, accuracy 0.5387045813586098\n",
      "Finished epoch 200, latest loss 2.3085975646972656, accuracy 0.5039494470774092\n",
      "Finished epoch 300, latest loss 2.280428886413574, accuracy 0.5521327014218009\n",
      "Finished epoch 400, latest loss 2.2779200077056885, accuracy 0.5284360189573459\n",
      "Finished epoch 500, latest loss 2.256657361984253, accuracy 0.5387045813586098\n",
      "Finished epoch 600, latest loss 2.2502005100250244, accuracy 0.5402843601895735\n",
      "Finished epoch 700, latest loss 2.2486824989318848, accuracy 0.5521327014218009\n",
      "Finished epoch 800, latest loss 2.2432501316070557, accuracy 0.5481832543443917\n",
      "Finished epoch 900, latest loss 2.238225221633911, accuracy 0.556872037914692\n"
     ]
    }
   ],
   "source": [
    "combined_model = train_multiclass_model(X_train, Y_train, n_inputs=192, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4732510288065844\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(combined_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2 : Storylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storylabels</th>\n",
       "      <th>title_vectors</th>\n",
       "      <th>subtitle_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kopf des Tages</td>\n",
       "      <td>[20.26102, -2.1764362, 12.056327, -8.353496, 2...</td>\n",
       "      <td>[12.673783, -13.09248, 8.577187, -2.7328134, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spiel</td>\n",
       "      <td>[-3.334474, -4.604315, -2.6970067, -2.6541345,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiel</td>\n",
       "      <td>[-0.60618734, 1.1090474, 3.5244317, -7.726671,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      storylabels                                      title_vectors  \\\n",
       "0  Kopf des Tages  [20.26102, -2.1764362, 12.056327, -8.353496, 2...   \n",
       "1           Spiel  [-3.334474, -4.604315, -2.6970067, -2.6541345,...   \n",
       "2           Spiel  [-0.60618734, 1.1090474, 3.5244317, -7.726671,...   \n",
       "\n",
       "                                    subtitle_vectors  \n",
       "0  [12.673783, -13.09248, 8.577187, -2.7328134, 9...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering for the most common ones\n",
    "\n",
    "storylabels_20 = standard_data_copy['storylabels'].value_counts().nlargest(20).index.tolist()\n",
    "\n",
    "standard_storylabels = standard_data_copy.copy()\n",
    "standard_storylabels = standard_storylabels[standard_storylabels['storylabels'].isin(storylabels_20)].reset_index()[['storylabels', 'title_vectors', 'subtitle_vectors']]\n",
    "\n",
    "standard_storylabels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36407, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent variable: bianry vector of length 20\n",
    "\n",
    "y = np.zeros((len(standard_storylabels), 20))\n",
    "print(y.shape)\n",
    "\n",
    "for row in range(y.shape[0]):\n",
    "    y_row = [1 if s == standard_storylabels['storylabels'][row] else 0 for s in storylabels_20]\n",
    "    y[row,] = y_row\n",
    "\n",
    "y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.6737833 , -13.09247971,   8.57718658,  -2.73281336,\n",
       "          9.55943489,   1.19442225,  13.35463333,  18.54079056,\n",
       "         -1.24317193, -16.44563866,  26.11481094, -23.8042469 ,\n",
       "        -19.78061295,  -1.20370197, -14.3854847 ,  21.38131714,\n",
       "         11.98632336,  11.43702793,  -8.80769539,   5.8185854 ,\n",
       "          9.41383076,  19.68308258,  12.65031338,   6.34458733,\n",
       "        -14.87839794, -12.42210007,  14.90303516,   5.76547098,\n",
       "          8.85460186,  13.4050703 , -14.50532913, -11.64571476,\n",
       "          6.06785011,   7.40806866,  18.20200348,   0.66248214,\n",
       "         -7.48345232,  -6.37721109,  30.55085945,  -2.74134064,\n",
       "        -18.50937462,  46.69207764,  14.90998268,  -1.3300662 ,\n",
       "         21.63993645,   9.69990635, -10.60776997, -12.7449646 ,\n",
       "         -7.96562004,  -2.69942284, -28.52653694,  -3.66213107,\n",
       "          3.77998972,   4.08382893,  10.05634022,  -5.16197395,\n",
       "         14.41419888,   7.13106537, -17.49291039,  -9.09768009,\n",
       "        -14.40098476,  -5.38680267, -15.8886013 , -10.017313  ,\n",
       "         -6.79507494,  12.58858109,  -5.66467857, -18.49414444,\n",
       "          1.37763619,  21.84117126, -10.74147129,   8.79939842,\n",
       "         23.5548439 ,  -6.04022217, -20.06015778,  -2.71913767,\n",
       "        -12.75486469,  -4.30656385,  -2.91261292, -17.43518829,\n",
       "         -6.46806765,   1.19207692, -11.48882484,  -0.17394084,\n",
       "         10.08629131,  16.67332077,  -6.58500385,   7.27330875,\n",
       "        -13.24323082,  31.27229691,  18.21424294,   0.77637053,\n",
       "          3.49404359,  14.81214142, -18.95225525,  -3.14274883],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_title = np.vstack(standard_storylabels['title_vectors'].to_numpy())\n",
    "X_title[0:2]\n",
    "\n",
    "X_subtitle = np.vstack(standard_storylabels['subtitle_vectors'].to_numpy())\n",
    "X_subtitle[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_train, X_title_test, Y_train, Y_test = train_test_split(X_title, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subtitle_train, X_subtitle_test, Y_train, Y_test = train_test_split(X_subtitle, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title_train = torch.tensor(X_title_train, dtype=torch.float32)\n",
    "X_title_test = torch.tensor(X_title_test, dtype=torch.float32)\n",
    "\n",
    "X_subtitle_train = torch.tensor(X_subtitle_train, dtype=torch.float32)\n",
    "X_subtitle_test = torch.tensor(X_subtitle_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n",
      "Finished epoch 0, latest loss 2.7086448669433594, accuracy 0.0\n",
      "Finished epoch 100, latest loss 2.1900155544281006, accuracy 0.0\n",
      "Finished epoch 200, latest loss 2.189687728881836, accuracy 0.0\n",
      "Finished epoch 300, latest loss 2.189687490463257, accuracy 0.0\n",
      "Finished epoch 400, latest loss 2.18967342376709, accuracy 0.0\n",
      "Finished epoch 500, latest loss 2.189673900604248, accuracy 0.0\n",
      "Finished epoch 600, latest loss 2.189673900604248, accuracy 0.0\n",
      "Finished epoch 700, latest loss 2.189673900604248, accuracy 0.0\n",
      "Finished epoch 800, latest loss 2.189673900604248, accuracy 0.0\n",
      "Finished epoch 900, latest loss 2.189673900604248, accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "model_titles = train_multiclass_model(X_title_train, Y_train, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34673698088332233\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(model_titles, X_title_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n",
      "Finished epoch 0, latest loss 2.792396068572998, accuracy 0.0\n",
      "Finished epoch 100, latest loss 2.294781446456909, accuracy 0.0\n",
      "Finished epoch 200, latest loss 2.2581024169921875, accuracy 0.0\n",
      "Finished epoch 300, latest loss 2.258202075958252, accuracy 0.0\n",
      "Finished epoch 400, latest loss 2.25809383392334, accuracy 0.0\n",
      "Finished epoch 500, latest loss 2.258094072341919, accuracy 0.0\n",
      "Finished epoch 600, latest loss 2.258089065551758, accuracy 0.0\n",
      "Finished epoch 700, latest loss 2.2580909729003906, accuracy 0.0\n",
      "Finished epoch 800, latest loss 2.2580976486206055, accuracy 0.0\n",
      "Finished epoch 900, latest loss 2.258089065551758, accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "model_subtitles = train_multiclass_model(X_subtitle_train, Y_train, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32179740716326083\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(model_subtitles, X_subtitle_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36407, 192)\n",
      "(36407, 20)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((np.vstack(standard_storylabels['title_vectors'].to_numpy()), np.vstack(standard_storylabels['subtitle_vectors'].to_numpy())), axis=1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42069)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n",
      "Finished epoch 0, latest loss 2.785167694091797, accuracy 0.0\n",
      "Finished epoch 100, latest loss 2.1517343521118164, accuracy 0.5\n",
      "Finished epoch 200, latest loss 2.1516098976135254, accuracy 0.5\n",
      "Finished epoch 300, latest loss 2.1516027450561523, accuracy 0.5\n",
      "Finished epoch 400, latest loss 2.1516025066375732, accuracy 0.5\n",
      "Finished epoch 500, latest loss 2.151602268218994, accuracy 0.5\n",
      "Finished epoch 600, latest loss 2.116236448287964, accuracy 0.5\n",
      "Finished epoch 700, latest loss 2.1162257194519043, accuracy 0.5\n",
      "Finished epoch 800, latest loss 2.1162257194519043, accuracy 0.5\n",
      "Finished epoch 900, latest loss 2.1162257194519043, accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "combined_model = train_multiclass_model(X_train, Y_train, n_inputs=192, n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43331136014062843\n"
     ]
    }
   ],
   "source": [
    "test_multiclass_model(combined_model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have processed the scraped data and trained classification models. The word2vec encoding of article title and subtitle is able to improve upon baseline accuracy on test data in both binary and multi-class classification tasks. However, there is still a large room for improvement. This could be achieved by \"bruteforcing\" the models - more layers, more nodes, more epochs etc., by using a more sofisticated network architecture such as RNN, or by using superior encodings - such as larger models included in the spacy module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/\n",
    "\n",
    "http://mitloehner.com/lehre/dsai1/\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "https://spacy.io/models/de\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
